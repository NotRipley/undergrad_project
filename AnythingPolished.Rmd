---
title: "AnythingPolished"
output: html_document
---

Compilation of polished productive code from other rmd files, in a format that can be sent over as a progress update. 

### The Simple Simulation with KMeans

```{r Libraries}

library(tidyverse) # general
library(mclust) # for the adj rand index

```

```{r Functions}

# m - number of rows per cluster
# n - number of dimensions for the dataset (number of columns)
# N - noise dimensions to be added to the dataset 'in post' of the generation
# k - clusters to generate
# Overlap - boolean variable, whether the variances of each cluster should be inflated s.t. they overlap, or should they be well-separated?
# Equal-In - boolean - should my clusters be spherical, or 'ovoid'?
# Equal-Out - equal variance between clusters, or randomly allocate? LEAVE FOR NOW
simple_data <- function(m, n, N, k, overlap, equalin) {
  
  # make sure nothing's gonna break
  stopifnot(
    is.logical(overlap), 
    is.logical(equalin)
    #is.logical(equalout)
  )
  
  # check some options based on our arguments
  if (overlap == TRUE) {
    p_var <- rep(0.5, k) 
  } else {
    p_var <- rep(0.2, k)
  }
  
  if (equalin == FALSE) {
    p_var <- abs(matrix(rnorm(k, p_var[[1]], 0.25),  nrow = 1, ncol = k)) # might need slight adjusting
    
  }
  
  unmerged <- list()
  
  # create centre data as separate matrices in 'unmerged'
  for (i in 1:k) {
    cat("generating cluster ", i, "... \n")
    unmerged[[i]] <- matrix(rnorm(m*n, i, p_var[[i]]), nrow = m, ncol = n)
    
    noise <- matrix(rnorm(N*m, mean = 0, sd = 0.3), nrow = m, ncol = N)
    unmerged[[i]] <- cbind(unmerged[[i]], noise)
    
    unmerged[[i]] <- cbind(unmerged[[i]], matrix(data = as.numeric(i), nrow = m, ncol = 1)) # add tag column
    
    cat("finished cluster ", i, "... \n")
  }
  
  cat("finished all clusters... \n")
  
  frame <- as.data.frame(do.call(rbind, unmerged)) # smush the matrices together
  
  names(frame)[1:n] <- paste0("dim", 1:n)
  if (N != 0) {
    names(frame)[(n + 1):(n + N)] <- paste0("noise", 1:N)
  }
  
  names(frame)[ncol(frame)] <- "Tag"
  
  return(frame)
  
}

# data - the dataframe that is generated 
# k - the true number of centres. hence, this will only work on our artificial simple data
# ignore_last - logical representing whether to cluster on the final col (i.e. is it a tag col)
kmeans_true_k <- function(data, k, ignore_last) {
  
  # a sprinkle of input checking
  stopifnot(
    is.data.frame(data),
    is.numeric(k),
    is.logical(ignore_last)
  )
  
  # drop last col if it's a tag col
  if (ignore_last == TRUE) {
    p_frame <- data[, -ncol(data)]
  } else {
    p_frame <- data
  }
  
  # kmeans on true k. In future can roll the estimation into this function maybe?
  kmobject <- kmeans(p_frame, k, iter.max = 20, nstart = 25)
  
  return(kmobject)
  
}

```

```{r Simulation}

# output will have 800 rows, 10^4 + 1 columns, one of which will be a tag column
sim_data <- simple_data(200, 10, 10^6 - 10, 4, TRUE, TRUE)

# 10 output points, starting small so we check it works
log_sequence <- unique(round(10^seq(1, 4, length.out = 10)))

scores <- numeric(length(log_sequence))

for (i in seq_along(log_sequence)) {
  current_slice <- sim_data[, 1:log_sequence[i]]
  kmobject <- kmeans_true_k(current_slice, 4, FALSE) # we don't ignore last because we never pass it all 10011
  scores[i] <- mclust::adjustedRandIndex(sim_data$Tag, kmobject$cluster)
  
  cat("Dimension", log_sequence[i], "gives score: ", round(scores[i], 4), " \n")
}

```

```{r Plot}



```

What do we take away from this? 

### Comparison of KMeans vs DBScan on Simple Data



### Comparison of Cluster Validation Metrics



### Performance on Splatter Data



### Performance on Real Data


