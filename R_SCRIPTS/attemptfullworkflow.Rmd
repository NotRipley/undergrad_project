---
title: "Draft Workflow for Clustering Algorithm Comparison on scRNA-seq Data"
output: html_document
---

### Data to be considered

First in consideration are the two datasets we will consider. We will use the pbmc dataset and one chosen splatter sim for now. So in this section, we load, label, process etc etc the two datasets and get them both into seurat objects. We also sort out where our files are going to be stored, and before moving on we clean up our working directory a bit.

## Metadata to store as output

KMeans needs k (number of centres) to be estimated or varied. DBScan needs eps (max distance between points) and minpts (min pts for a cluster) the same. Louvain needs resolution to be estimated or varied.

So for each clustering attempt, we store:
- the algorithm info
  - the type
  - the parameters
- the dataset info
  - the name
  - the number of cells
  - the number of features
  - the number of PCs
  - (maybe here is whether we use UMAP or not?)
- the run info
  - which repetition this is
  - the random seed
  - the time at the start
  - the runtime 
- the cluster results
  - the number detected
  - the sizes of them
- the quality metrics
  - silhouette avg
  - silhouette sd - because silhouette is a per-node property and not initially a gobal one, it has some variance
  - the adj rand index
  - any more that we want - this can be considered an easy way to expand the scope i think
- then any biological context that we want to add

## How many repetitions

A lot of estimation for DBScan parameters involves computationally finding an 'elbow', which is fine but a bit clunky. AI suggests a grid search on the parameters and just storing all of them, but this seems really inefficient because I then just don't care about the ones that aren't optimal. 

But however we do it, we go with 30-50 repetitions by unique algorithm/parameter/dataset combination. And then we can extract the quality metrics from these 30-50 repetitions.

### Algorithms for Comparison

We want to compare KMeans, DBScan, and the Louvain Algorithm. If we expanded this scope, it would be to the other standard options in FindClusters(algorithm=...) from seurat.

### Quality Metrics

For our splatter data, we will have access to the ground truth. In this case, we can use the adjusted rand index for the cluster quality assessment. We also do the silhouette score. 


### We Begin

```{r Libraries}

suppressPackageStartupMessages({
  library(splatter)
  library(scater)
  library(Seurat)
  library(tidyverse)
  library(cluster)
})

```

```{r Functions}

# batchCells - a vector giving the number of cells per batch, ie two batches with 100 cells is (100, 100)
# group.prob - vector specifying probabilities per group, ie (0.5, 0.5) will likely give two same sized groups
# de.prob - probability that genes will be DE by group(?) i.e. that they'll differ more than just noise
# nGenes - number of genes to simulate
# all else we leave as default values. 
seurat_from_params <- function(batchCells, group.prob, de.prob, nGenes, proj_name) {
  
  stopifnot(
    is.numeric(batchCells),
    is.numeric(group.prob),
    is.numeric(de.prob),
    is.numeric(nGenes),
    is.character(proj_name)
  )
  
  params <- newSplatParams()
  
  params <- setParams(params, update = list(
    batchCells = batchCells, 
    group.prob = group.prob, 
    de.prob = de.prob,
    nGenes = nGenes
    ))
  
  sim <- splatSimulate(params, method = "groups")
  
  counts_matrix <- counts(sim)
  seurat_obj <- CreateSeuratObject(counts = counts_matrix, project = proj_name)
  
  # then we want to add the true labelling in case we want to do arandi
  seurat_obj$true_labelling <- colData(sim)$Group
  
  return(seurat_obj)
  
}


# seurat_object - on which we want to perform our clustering
preprocess <- function(seurat_object) {
  # takes seurat object and performs sctransform and pca steps
  
  stopifnot(
    (class(seurat_object) == "Seurat")
  )
  
  seurat_object <- SCTransform(seurat_object, verbose = FALSE)
  
  seurat_object <- RunPCA(seurat_object, verbose = FALSE)
  
  return(seurat_object)
  
}


# seurat_object - a processed seurat object
# npcs - number of pcs to consider
# k - numer of clusters
run_kmeans <- function(seurat_object, npcs, k) {
  # takes a processed seurat object, runs kmeans on it and returns an object of class kmeans
  
  stopifnot(
    (class(seurat_object) == "Seurat"), 
    is.numeric(npcs),
    is.numeric(k)
  )
  
  pc_embeddings <- Embeddings(seurat_object, reduction = "pca")[, 1:npcs]
  
  kmobject <- kmeans(pc_embeddings, centers = k, nstart = 25)
  
  return(kmobject)
  
}


# pc_embeddings - the pc embeddings from running Embeddings(seurat_object, reduction = "pca")
# clustering - vector of cluster assignments eg from kmeans$cluster
silhouette_score <- function(pc_embeddings, clustering) {
  # takes pc embeddings and clustering and returns silhouette mean, then sd
  
  sil <- silhouette(clustering, dist(pc_embeddings))
  
  return(list(mean(sil[, 3]), sd(sil[, 3])))
  
}

```

```{r Simulated Dataset}

simulated1 <- seurat_from_params(
  batchCells = 500,
  group.prob = c(0.25, 0.25, 0.25, 0.25),
  de.prob = 0.2, 
  nGenes = 3000,
  proj_name = "simulated1"
)

```

```{r pbmc Dataset}

pbmc_data <- Read10X("C:/Users/fmhfl/Desktop/Undergrad Project/undergrad_project/DATA/filtered_gene_bc_matrices/hg19/")

pbmc <- CreateSeuratObject(counts = pbmc_data)

```


```{r Init Results Dataframe}

RESULTS <- tibble(
  run_name = character(),
  algorithm = character(),
  
  k = integer(),
  eps = numeric(),
  minpts = integer(),
  resolution = numeric(),
  
  dataset = character(),
  ncells = integer(),
  nfeatures = integer(),
  npcs = integer(),
  
  repindex = integer(),
  random_seed = numeric(),
  start_time = POSIXct(),
  runtime = numeric(),
  
  cluster_numer = integer(),
  cluster_sizes = list(),
  
  sil_avg = numeric(),
  sil_sd = numeric(),
  arandi = numeric()
)


```

one thing we really need to check is if the pbmc is single cell - 99% sure it is but conscious I haven't actually checked. 

```{r Scratch}

p_simulated1 <- preprocess(simulated1)

km_simulated1 <- run_kmeans(p_simulated1, 30, 4)

# ok so this seems to be working about as intended.
# since we're not going to have to generalise to dataset (we're only going to do 2 or 3) I'm ok with choosing k manually, for now at least. 
# now we get our index extraction. so which did we wanna do? silhouette first. Then we can do a run of 50 reps and get 50 rows in our tibble named draft or smth. because we haven't brought through the true clustering yet, we can't quite do arandi. so for now we do the most useful one which will be silhouette.

# but, what we want to pass to our silhouette score function, is just the original matrix (sparse or not who cares) and the clustering tag. so that we can modularise based on algorithm and index. 

embed1 <- Embeddings(p_simulated1, reduction = "pca")
sil1 <- silhouette_score(embed1, km_simulated1$cluster)

# so given several factors that should affect the clustering: simulated (makes it better in this case), kmeans (worse since algorithm not the best), given true number of clusters (better), we see at least a reasonable average sil score of .258 in this first simulation, with a sd of 0.041. let's repeat this a bunch, and see if we can then average them.

```



```{r Trying to Spit out Some Results mostly AI SLOP}

p_simulated1 <- preprocess(simulated1)

tib1 <- tibble()

for (i in 1:50) {
  # Set parameters
  k <- 4
  n_pcs <- 30
  rep_index <- i
  seed <- 123 + i  # Different seed per rep is standard practice
  
  # Start timing
  start_time <- Sys.time()
  
  # Set seed and run clustering
  set.seed(seed)
  kmobject <- run_kmeans(p_simulated1, npcs = n_pcs, k = 4)
  
  # Calculate silhouette
  sil_both <- silhouette_score(Embeddings(p_simulated1, reduction = "pca"), kmobject$cluster)
  sil_avg <- sil_both[[1]]
  sil_sd <- sil_both[[2]]
  
  # End timing
  end_time <- Sys.time()
  runtime <- as.numeric(difftime(end_time, start_time, units = "secs"))
  
  # Compile results
  results <- tibble(
    algorithm = "kmeans",
    parameters = paste0("k=", k, ", nstart=25"),
    dataset = "simulated1",  # or whatever your dataset name is
    n_cells = ncol(p_simulated1),
    n_features = nrow(p_simulated1),
    n_pcs = n_pcs,
    repetition = i,
    seed = seed,
    start_time = start_time,
    runtime_secs = runtime,
    n_clusters = k,
    cluster_sizes = list(table(kmobject$cluster)),  # stores as list column
    sil_avg = sil_avg,
    sil_sd = sil_sd
  )
  
  tib1 <- bind_rows(tib1, results)
  
}

print(tib1)

#interesting, the sil avg and sd are identical through these 50. This is a bit weird, will need to check this. But! this is very good. This is the beginning of usable data. 

```




